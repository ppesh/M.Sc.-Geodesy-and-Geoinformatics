{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von musterUe3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHE4r41P8aOk"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay as CMD\n",
        "from torch.utils.data import TensorDataset \n",
        "from torch.utils.data import DataLoader \n",
        "from torchvision import datasets, models, transforms\n",
        "from google.colab import drive\n",
        "\n",
        "# Connect to your google drive:\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/MusterUe/src')\n",
        "\n",
        "from utils import *\n",
        "\n",
        "\n",
        "## Settings:\n",
        "pretrained = True    \n",
        "architecture = models.resnet18      # (funcion pointer)\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.1\n",
        "batch_size = 32\n",
        "device = 'cuda'                     # 'cuda' or 'cpu'\n",
        "\n",
        "train_image = [3, 12]               # [row, column]\n",
        "valid_image = [3, 13]               # [row, column]\n",
        "test_image  = [2, 10]               # [row, column]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bf4NBYeIYDE"
      },
      "source": [
        "## Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wEoHzC6KIvf"
      },
      "source": [
        "class_names = {0: 'building', 1: 'car', 2: 'clutter'}   # label: name\n",
        "\n",
        "crops_train, gt_train = load_crops(*train_image)\n",
        "crops_valid, gt_valid = load_crops(*valid_image)\n",
        "\n",
        "print(\"Number of input channels:      \", crops_train.shape[2])\n",
        "print(\"Number of training samples:    \", crops_train.shape[-1])\n",
        "print(\"Number of validation samples:  \", crops_valid.shape[-1])\n",
        "\n",
        "# Plot 8 random samples (RGB):\n",
        "plot_samples(crops_train, gt_train, class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vNYrus24aDO"
      },
      "source": [
        "## Prepare Data for Network\n",
        "Use `dataloaders` and `datasets` to **feed data mini-batch-wise** to network. Can also be used for data-augmentation, e.g. see `transforms` for `ImageFolder` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7xsRnJuv_5_"
      },
      "source": [
        "def prep_data(images, labels, batch_size=64, shuffle=False):\n",
        "  images_ = np.moveaxis(images, [0, 1, 2, 3], [2,3,1,0]) # (H,W,C,N) => (N,Câ€‹,H,W) \n",
        "  images_ = torch.tensor(images_).float()\n",
        "  labels_ = torch.tensor(labels).squeeze().long()\n",
        "  dataset = TensorDataset(images_, labels_)\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "  return dataloader\n",
        "\n",
        "dataloader_train = prep_data(crops_train, gt_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#\n",
        "# TODO: create validation dataloader\n",
        "dataloader_valid = prep_data(crops_valid, gt_valid, batch_size=batch_size, shuffle=True)\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdKkGZldr0Rg"
      },
      "source": [
        "## Create Network\n",
        "**Download** (pretrained) network.\n",
        "**Replace first layer** to accept `cin = 5 = [RGBIRnDSM]` input channels. **Replace last layer** to output probabilities for `cout = 3 = [building, car, clutter]` classes. \n",
        "We make sure that all layers use the same format (`float()`) and move the network to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXjueqSrr2ak"
      },
      "source": [
        "net = architecture(pretrained=True, progress=True)\n",
        "# print(net) # Display network architecture\n",
        "cin = crops_train.shape[2]\n",
        "cout = len(class_names)\n",
        "\n",
        "#\n",
        "# TODO: replace first and last network layer.\n",
        "#  - Find the names of those layers trough print(net)\n",
        "#  - Redefine those layers with net.layername = torch.nn.XYZ(...)\n",
        "#  - For the first layer (torch.nn.Conv2D), use the same parameters except the number of input channels (first parameter)\n",
        "net.conv1 = torch.nn.Conv2d(cin, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "#  - For the last layer (torch.nn.Linear), use the same parameters except out_features.\n",
        "net.fc = torch.nn.Linear(in_features=512, out_features=cout, bias=True)\n",
        "#\n",
        "\n",
        "\n",
        "net.float();\n",
        "\n",
        "#\n",
        "# TODO: transfer network to the device devined in settings.\n",
        "net.to(device)\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RY7VZs2ueKa"
      },
      "source": [
        "## Training / Fine Tuning\n",
        "`net.train()` to set network (-modules) in training mode or `net.eval()` for inference, which relevant e.g. with dropout and Batchnormalization.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhkHmkf0IFeH"
      },
      "source": [
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "loss_fu = nn.CrossEntropyLoss()\n",
        "\n",
        "log = []\n",
        "tic = time.time()\n",
        "\n",
        "for i in range(100):\n",
        "  ## Training step\n",
        "  net.train()\n",
        "  rl = []   # running loss\n",
        "  ra = []   # running accuracy\n",
        "  for batch in dataloader_train:\n",
        "    inputs = batch[0].to(device)\n",
        "    labels = batch[1].to(device)\n",
        "    #\n",
        "    # TODO: training over each mini-batch (see demo script)\n",
        "    optimizer.zero_grad()           # Set gradient buffers to zero to prevent accumulations\n",
        "    outputs = net(inputs)           # Forward pass\n",
        "    loss = loss_fu(outputs, labels) # Calc loss\n",
        "    loss.backward()                 # Backpropagation: compute gradients\n",
        "    optimizer.step()                # Parameter update\n",
        "    # print(\"loss:\", loss)\n",
        "    # \n",
        "\n",
        "    oa = torch.sum(torch.argmax(outputs,1) == labels).item() / len(labels) * 100\n",
        "    rl.append(loss.item())\n",
        "    ra.append(oa)\n",
        "\n",
        "  loss = np.mean(rl)\n",
        "  acc = np.mean(ra)\n",
        "  print(\"Epoch %2d,  loss: %.4f,  acc: %5.1f\" % (i, loss, acc), end='')\n",
        "  log.append({'loss': loss, 'acc': acc})\n",
        "\n",
        "  ## Validation step\n",
        "  net.eval()\n",
        "\n",
        "  #\n",
        "  # TODO: run validation set trough the network. Record loss and accuracy\n",
        "  cl = []   # contrl loss\n",
        "  ca = []   # control accuracy\n",
        "  for batch in dataloader_valid:\n",
        "    inputs = batch[0].to(device)\n",
        "    labels = batch[1].to(device)\n",
        "    outputs = net(inputs)           # Forward pass\n",
        "    loss = loss_fu(outputs, labels) # Calc loss\n",
        "  \n",
        "    oa = torch.sum(torch.argmax(outputs,1) == labels).item() / len(labels) * 100\n",
        "    cl.append(loss.item())\n",
        "    ca.append(oa)\n",
        "\n",
        "  loss = np.mean(cl)\n",
        "  acc = np.mean(ca)\n",
        "  #\n",
        "\n",
        "  print(\",  valid_loss: %.4f,  valid_acc: %5.1f\" % (loss, acc))\n",
        "  log[-1]['valid_loss'] = loss; \n",
        "  log[-1]['valid_acc'] = acc\n",
        "\n",
        "print(\"Finished Training after:\", time.time()-tic, \"sec.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_M6TRCn0eTM"
      },
      "source": [
        "## Plotting Training Metrics:\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "def p(ax, d, t):\n",
        "  ax.plot(d)\n",
        "  ax.set_title(t)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.grid(True)\n",
        "p(ax1, [x['loss'] for x in log], 'loss')\n",
        "p(ax2, [x['acc'] for x in log], 'acc [%]')\n",
        "\n",
        "#\n",
        "# TODO: Plot valid metrics into same axes.\n",
        "p(ax1, [x['valid_loss'] for x in log], 'loss')\n",
        "p(ax2, [x['valid_acc'] for x in log], 'acc [%]')\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzNxUt2D41hC"
      },
      "source": [
        "## Testing\n",
        "Inference on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmhVv1ZXNqEQ"
      },
      "source": [
        "net.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "  #\n",
        "  # TODO: \n",
        "  #  - Import test crops & create dataloader\n",
        "  crops_test, gt_test = load_crops(*test_image)\n",
        "  dataloader_test = prep_data(crops_test, gt_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "  preds = torch.zeros(0).to(device)\n",
        "  gt = torch.zeros(0, dtype=torch.int).to(device)\n",
        "\n",
        "  probs = []\n",
        "\n",
        "  for batch in dataloader_test:\n",
        "    inputs = batch[0].to(device)\n",
        "    gt = torch.cat((gt, batch[1].to(device)))\n",
        "    outputs = net(inputs)\n",
        "    preds = torch.cat((preds, nn.functional.softmax(outputs)))\n",
        "\n",
        "probs, preds = torch.max(preds, 1)\n",
        "probs = probs.detach().cpu()\n",
        "preds = preds.detach().cpu()\n",
        "gt = gt.detach().cpu()\n",
        "\n",
        "  #  - Over all mini-batches:\n",
        "  #     - Predict crop-wise network outputs for test dataset\n",
        "  #     - collect the corresponding gt\n",
        "  #  - Bring predictions & gt to cpu with .detach().cpu().\n",
        "  #  - Use torch.nn.functional.softmax to convert the network outputs to probabilities.\n",
        "  #  - Use torch.max to select per sample the class with the highest probability as prediction.\n",
        "  #\n",
        "  #  => variables (expected in further script):\n",
        "  #        preds  = predicted class label per crop / bounding box.\n",
        "  #        probs  = probabilitiy of predicted class label per crop / bounding box.\n",
        "  #\n",
        "  # Tips:\n",
        "  #   - use torch.cat() to concatinate list of tensors (per mini batch) to a single tensor.\n",
        "  #   - max, argmax = torch.max()\n",
        "  #\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAzRl4Eb12tz"
      },
      "source": [
        "## Evaluating Test Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmFOurSK140h"
      },
      "source": [
        "# Overall Accuracy etc.:\n",
        "acc       = sklearn.metrics.accuracy_score(gt, preds)\n",
        "recall    = sklearn.metrics.recall_score(gt, preds, average=None)\n",
        "precision = sklearn.metrics.precision_score(gt, preds, average=None)\n",
        "f1        = sklearn.metrics.f1_score(gt, preds, average=None)\n",
        "print(\"Overall Test Accuracy: %5.1f %%\" % (acc*100))\n",
        "print(\"Recall:    \", recall*100, '[%]')\n",
        "print(\"Precision: \", precision*100, '[%]')\n",
        "print(\"F1 score:  \", f1*100, '[%]')\n",
        "\n",
        "# Confusion Matrix:\n",
        "cm = confusion_matrix(gt, preds)\n",
        "disp = CMD(confusion_matrix=cm, display_labels=list(class_names.values()))\n",
        "disp = disp.plot(include_values=True, cmap='Greys', ax=None, xticks_rotation='horizontal')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNtKRk1AlZsH"
      },
      "source": [
        "## Plot Test Results\n",
        "After loading the **original bounding box coordinates** and the **RGB test image**, plot predictions onto RGB image and save to drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef-miRBnlCeL"
      },
      "source": [
        "img = load_img(*test_image)\n",
        "bbs = load_bbs(*test_image)\n",
        "\n",
        "img_name = '%d_%d ' % tuple(test_image)\n",
        "colors = ['b', 'y', 'r']\n",
        "plot_bbs(img, bbs, gt,           colors=colors, title=img_name + ' GT')\n",
        "plot_bbs(img, bbs, preds, probs, colors=colors, title=img_name + ' Prediction')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}